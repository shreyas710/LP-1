{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIR Assign 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "POS tag list:\n",
        "\n",
        "CC\tcoordinating conjunction\n",
        "CD\tcardinal digit\n",
        "DT\tdeterminer\n",
        "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
        "FW\tforeign word\n",
        "IN\tpreposition/subordinating conjunction\n",
        "JJ\tadjective\t'big'\n",
        "JJR\tadjective, comparative\t'bigger'\n",
        "JJS\tadjective, superlative\t'biggest'\n",
        "LS\tlist marker\t1)\n",
        "MD\tmodal\tcould, will\n",
        "NN\tnoun, singular 'desk'\n",
        "NNS\tnoun plural\t'desks'\n",
        "NNP\tproper noun, singular\t'Harrison'\n",
        "NNPS\tproper noun, plural\t'Americans'\n",
        "PDT\tpredeterminer\t'all the kids'\n",
        "POS\tpossessive ending\tparent\\'s\n",
        "PRP\tpersonal pronoun\tI, he, she\n",
        "PRP$\tpossessive pronoun\tmy, his, hers\n",
        "RB\tadverb\tvery, silently,\n",
        "RBR\tadverb, comparative\tbetter\n",
        "RBS\tadverb, superlative\tbest\n",
        "RP\tparticle\tgive up\n",
        "TO\tto\tgo 'to' the store.\n",
        "UH\tinterjection\terrrrrrrrm\n",
        "VB\tverb, base form\ttake\n",
        "VBD\tverb, past tense\ttook\n",
        "VBG\tverb, gerund/present participle\ttaking\n",
        "VBN\tverb, past participle\ttaken\n",
        "VBP\tverb, sing. present, non-3d\ttake\n",
        "VBZ\tverb, 3rd person sing. present\ttakes\n",
        "WDT\twh-determiner\twhich\n",
        "WP\twh-pronoun\twho, what\n",
        "WP$\tpossessive wh-pronoun\twhose\n",
        "WRB\twh-abverb\twhere, when\n",
        "'''\n",
        "\n",
        "import nltk   # natural language toolkit to work with human language\n",
        "from nltk.corpus import state_union   # get the speech \n",
        "from nltk.tokenize import PunktSentenceTokenizer    # unsupervised tokenizer"
      ],
      "metadata": {
        "id": "6L-zErB3x5fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('state_union')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je_iAdKbggey",
        "outputId": "aa12e710-6355-474d-beb3-4902c7032b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Package state_union is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovKUH6wFmbpK"
      },
      "source": [
        "train_text = state_union.raw(\"2005-GWBush.txt\")   # training data\n",
        "sample_text = state_union.raw(\"2006-GWBush.txt\")    # testing data\n",
        "\n",
        "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)    # train the Punkt tokenizer\n",
        "\n",
        "tokenized = custom_sent_tokenizer.tokenize(sample_text)   # tokenize\n",
        "\n",
        "# print(tokenized)\n",
        "\n",
        "# tag all parts of speech per sentence\n",
        "def process_content():\n",
        "  try:\n",
        "    for i in tokenized:\n",
        "      words = nltk.word_tokenize(i)\n",
        "      tagged = nltk.pos_tag(words)\n",
        "      print(tagged)   # tagged speech\n",
        "\n",
        "      # <RB.?>* = \"0 or more of any tense of adverb\" \n",
        "      # <VB.?>* = \"0 or more of any tense of verb\" \n",
        "      # <NNP>+ = \"1 or more proper nouns\"\n",
        "      # <NN>? = \"0 or one singular noun\"\n",
        "      chunkGram = r\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\n",
        "\n",
        "      chunkParser = nltk.RegexpParser(chunkGram)    # parse the chunk\n",
        "\n",
        "      chunked = chunkParser.parse(tagged)   # parse the tagged speech\n",
        "\n",
        "      # get the chunks\n",
        "      for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
        "          print(subtree)\n",
        "\n",
        "      chunked.draw()\n",
        "\n",
        "  except Exception as e:\n",
        "    return\n",
        "\n",
        "process_content()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}